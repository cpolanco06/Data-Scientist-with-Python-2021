{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Steps of a semi-join\n",
    "\n",
    "#In the last video, you were shown how to perform a semi-join with pandas. In this exercise, you'll solidify your understanding\n",
    "#of the necessary steps. Recall that a semi-join filters the left table to only the rows where a match exists in both the left\n",
    "#and right tables.\n",
    "\n",
    "#Sort the steps in the correct order of the technique shown to perform a semi-join in pandas.\n",
    "\n",
    "#Merge the left and right tables on key column using an inner-join.\n",
    "\n",
    "#Search if the key column in the left table is in the merged tables using the .isin() method creating a Boolean Series.\n",
    "\n",
    "#Subset the rows of the left table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   srid     lname    fname            title  hire_date  \\\n",
      "0     1     Adams   Andrew  General Manager 2002-08-14   \n",
      "1     2   Edwards    Nancy    Sales Manager 2002-05-01   \n",
      "5     6  Mitchell  Michael       IT Manager 2003-10-17   \n",
      "6     7      King   Robert         IT Staff 2004-01-02   \n",
      "7     8  Callahan    Laura         IT Staff 2004-03-04   \n",
      "\n",
      "                     email  \n",
      "0   andrew@chinookcorp.com  \n",
      "1    nancy@chinookcorp.com  \n",
      "5  michael@chinookcorp.com  \n",
      "6   robert@chinookcorp.com  \n",
      "7    laura@chinookcorp.com  \n"
     ]
    }
   ],
   "source": [
    "#Performing an anti-join\n",
    "\n",
    "import pandas as pd\n",
    "employees = pd.read_csv('datasets/employees.csv')\n",
    "employees['hire_date'] = pd.to_datetime(employees['hire_date'], format=\"%Y/%m/%d\")\n",
    "top_cust = pd.read_csv('datasets/top_cust.csv')\n",
    "\n",
    "#In our music streaming company dataset, each customer is assigned an employee representative to assist them. In this exercise,\n",
    "#filter the employee table by a table of top customers, returning only those employees who are not assigned to a customer. The\n",
    "#results should resemble the results of an anti-join. The company's leadership will assign these employees additional training\n",
    "#so that they can work with high valued customers.\n",
    "\n",
    "#The top_cust and employees tables have been provided for you.\n",
    "\n",
    "# Merge employees and top_cust\n",
    "empl_cust = employees.merge(top_cust, on='srid', \n",
    "                                 how='left', indicator=True)\n",
    "\n",
    "# Select the srid column where _merge is left_only\n",
    "srid_list = empl_cust.loc[empl_cust['_merge'] == 'left_only', 'srid']\n",
    "\n",
    "# Get employees not working with top customers\n",
    "print(employees[employees['srid'].isin(srid_list)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   gid  tid      name\n",
      "0   19    4  TV Shows\n",
      "1   21    2     Drama\n",
      "2   22    1    Comedy\n"
     ]
    }
   ],
   "source": [
    "#Performing a semi-join\n",
    "\n",
    "import pandas as pd\n",
    "non_mus_tcks = pd.read_csv('datasets/non_mus_tcks.csv', sep=';')\n",
    "top_invoices = pd.read_csv('datasets/top_invoices.csv')\n",
    "genres = pd.read_csv('datasets/genres.csv')\n",
    "\n",
    "#Some of the tracks that have generated the most significant amount of revenue are from TV-shows or are other non-musical audio.\n",
    "#You have been given a table of invoices that include top revenue-generating items. Additionally, you have a table of\n",
    "#non-musical tracks from the streaming service. In this exercise, you'll use a semi-join to find the top revenue-generating\n",
    "#non-musical tracks..\n",
    "\n",
    "#The tables non_mus_tcks, top_invoices, and genres have been loaded for you.\n",
    "\n",
    "# Merge the non_mus_tck and top_invoices tables on tid\n",
    "tracks_invoices = non_mus_tcks.merge(top_invoices, on='tid')\n",
    "\n",
    "# Use .isin() to subset non_mus_tcks to rows with tid in tracks_invoices\n",
    "top_tracks = non_mus_tcks[non_mus_tcks['tid'].isin(tracks_invoices['tid'])]\n",
    "\n",
    "# Group the top_tracks by gid and count the tid rows\n",
    "cnt_by_gid = top_tracks.groupby(['gid'], as_index=False).agg({'tid':'count'})\n",
    "\n",
    "# Merge the genres table to cnt_by_gid on gid and print\n",
    "print(cnt_by_gid.merge(genres, on='gid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   aid             composer  gid  mtid                     name   tid  u_price\n",
      "0  152  J.Hetfield/L.Ulrich    3     1                  Battery  1853     0.99\n",
      "1  152            K.Hammett    3     1        Master Of Puppets  1854     0.99\n",
      "4  152  J.Hetfield/L.Ulrich    3     1        Disposable Heroes  1857     0.99\n",
      "0  154                  NaN    3     1     Fight Fire With Fire  1874     0.99\n",
      "1  154                  NaN    3     1       Ride The Lightning  1875     0.99\n",
      "2  154                  NaN    3     1  For Whom The Bell Tolls  1876     0.99\n",
      "3  154                  NaN    3     1            Fade To Black  1877     0.99\n",
      "4  154                  NaN    3     1        Trapped Under Ice  1878     0.99\n",
      "0  155                  NaN    3     1                  Frantic  1882     0.99\n",
      "1  155                  NaN    3     1                St. Anger  1883     0.99\n",
      "2  155                  NaN    3     1     Some Kind Of Monster  1884     0.99\n",
      "3  155                  NaN    3     1             Dirty Window  1885     0.99\n",
      "4  155                  NaN    3     1            Invisible Kid  1886     0.99\n",
      "\n",
      "\n",
      "    aid             composer  gid  mtid                     name   tid  \\\n",
      "0   152  J.Hetfield/L.Ulrich    3     1                  Battery  1853   \n",
      "1   152            K.Hammett    3     1        Master Of Puppets  1854   \n",
      "2   152  J.Hetfield/L.Ulrich    3     1        Disposable Heroes  1857   \n",
      "3   154                  NaN    3     1     Fight Fire With Fire  1874   \n",
      "4   154                  NaN    3     1       Ride The Lightning  1875   \n",
      "5   154                  NaN    3     1  For Whom The Bell Tolls  1876   \n",
      "6   154                  NaN    3     1            Fade To Black  1877   \n",
      "7   154                  NaN    3     1        Trapped Under Ice  1878   \n",
      "8   155                  NaN    3     1                  Frantic  1882   \n",
      "9   155                  NaN    3     1                St. Anger  1883   \n",
      "10  155                  NaN    3     1     Some Kind Of Monster  1884   \n",
      "11  155                  NaN    3     1             Dirty Window  1885   \n",
      "12  155                  NaN    3     1            Invisible Kid  1886   \n",
      "\n",
      "    u_price  \n",
      "0      0.99  \n",
      "1      0.99  \n",
      "2      0.99  \n",
      "3      0.99  \n",
      "4      0.99  \n",
      "5      0.99  \n",
      "6      0.99  \n",
      "7      0.99  \n",
      "8      0.99  \n",
      "9      0.99  \n",
      "10     0.99  \n",
      "11     0.99  \n",
      "12     0.99  \n",
      "\n",
      "\n",
      "   aid  gid  mtid                     name   tid  u_price\n",
      "0  152    3     1                  Battery  1853     0.99\n",
      "1  152    3     1        Master Of Puppets  1854     0.99\n",
      "4  152    3     1        Disposable Heroes  1857     0.99\n",
      "0  154    3     1     Fight Fire With Fire  1874     0.99\n",
      "1  154    3     1       Ride The Lightning  1875     0.99\n",
      "2  154    3     1  For Whom The Bell Tolls  1876     0.99\n",
      "3  154    3     1            Fade To Black  1877     0.99\n",
      "4  154    3     1        Trapped Under Ice  1878     0.99\n",
      "0  155    3     1                  Frantic  1882     0.99\n",
      "1  155    3     1                St. Anger  1883     0.99\n",
      "2  155    3     1     Some Kind Of Monster  1884     0.99\n",
      "3  155    3     1             Dirty Window  1885     0.99\n",
      "4  155    3     1            Invisible Kid  1886     0.99\n"
     ]
    }
   ],
   "source": [
    "#Concatenation basics\n",
    "\n",
    "import pandas as pd\n",
    "tracks_master = pd.read_csv('datasets/tracks_master.csv')\n",
    "tracks_ride = pd.read_csv('datasets/tracks_ride.csv')\n",
    "tracks_st = pd.read_csv('datasets/tracks_st.csv')\n",
    "\n",
    "#You have been given a few tables of data with musical track info for different albums from the metal band, Metallica. The track\n",
    "#info comes from their Ride The Lightning, Master Of Puppets, and St. Anger albums. Try various features of the .concat() method\n",
    "#by concatenating the tables vertically together in different ways.\n",
    "\n",
    "#The tables tracks_master, tracks_ride, and tracks_st have loaded for you.\n",
    "\n",
    "# Concatenate the tracks\n",
    "tracks_from_albums = pd.concat([tracks_master, tracks_ride, tracks_st],\n",
    "                               sort=True)\n",
    "print(tracks_from_albums)\n",
    "print('\\n')\n",
    "\n",
    "# Concatenate the tracks so the index goes from 0 to n-1\n",
    "tracks_from_albums = pd.concat([tracks_master, tracks_ride, tracks_st],\n",
    "                               ignore_index=True,\n",
    "                               sort=True)\n",
    "print(tracks_from_albums)\n",
    "print('\\n')\n",
    "\n",
    "# Concatenate the tracks, show only columns names that are in all tables\n",
    "tracks_from_albums = pd.concat([tracks_master, tracks_ride, tracks_st],\n",
    "                               join='inner',\n",
    "                               sort=True)\n",
    "print(tracks_from_albums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Concatenating with keys\n",
    "\n",
    "import pandas as pd\n",
    "inv_jul = pd.read_csv('datasets/inv_jul.csv')\n",
    "inv_jul['invoice_date'] = pd.to_datetime(inv_jul['invoice_date'], format=\"%Y/%m/%d\")\n",
    "inv_aug = pd.read_csv('datasets/inv_aug.csv')\n",
    "inv_aug['invoice_date'] = pd.to_datetime(inv_aug['invoice_date'], format=\"%Y/%m/%d\")\n",
    "inv_sep = pd.read_csv('datasets/inv_sep.csv')\n",
    "inv_sep['invoice_date'] = pd.to_datetime(inv_sep['invoice_date'], format=\"%Y/%m/%d\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#The leadership of the music streaming company has come to you and asked you for assistance in analyzing sales for a recent\n",
    "#business quarter. They would like to know which month in the quarter saw the highest average invoice total. You have been given\n",
    "#three tables with invoice data named inv_jul, inv_aug, and inv_sep. Concatenate these tables into one to create a graph of the\n",
    "#average monthly invoice total.\n",
    "\n",
    "# Concatenate the tables and add keys\n",
    "inv_jul_thr_sep = pd.concat([inv_jul, inv_aug, inv_sep], \n",
    "                            keys=['7Jul', '8Aug', '9Sep'])\n",
    "\n",
    "# Group the invoices by the index keys and find avg of the total column\n",
    "avg_inv_by_month = inv_jul_thr_sep.groupby(level=0).agg({'total': 'mean'})\n",
    "\n",
    "# Bar plot of avg_inv_by_month\n",
    "avg_inv_by_month.plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'invoice_items' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-c5a3650ac792>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# Merge metallica_tracks and invoice_items\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mtracks_invoices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetallica_tracks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minvoice_items\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'tid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# For each tid and name sum the quantity sold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'invoice_items' is not defined"
     ]
    }
   ],
   "source": [
    "#Using the append method\n",
    "\n",
    "#The .concat() method is excellent when you need a lot of control over how concatenation is performed. However, if you do not\n",
    "#need as much control, then the .append() method is another option. You'll try this method out by appending the track lists\n",
    "#together from different Metallica albums. From there, you will merge it with the invoice_items table to determine which track\n",
    "#sold the most.\n",
    "\n",
    "#The tables tracks_master, tracks_ride, tracks_st, and invoice_items have loaded for you.\n",
    "\n",
    "# Use the .append() method to combine the tracks tables\n",
    "metallica_tracks = tracks_ride.append([tracks_master, tracks_st], sort=False)\n",
    "\n",
    "# Merge metallica_tracks and invoice_items\n",
    "tracks_invoices = metallica_tracks.merge(invoice_items, on='tid')\n",
    "\n",
    "# For each tid and name sum the quantity sold\n",
    "tracks_sold = tracks_invoices.groupby(['tid','name']).agg({'quantity': 'sum'})\n",
    "\n",
    "# Sort in decending order by quantity and print the results\n",
    "print(tracks_sold.sort_values(by='quantity', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   artid       name  aid                                  title\n",
      "0      1      AC/DC    1  For Those About To Rock We Salute You\n",
      "1      1      AC/DC    4                      Let There Be Rock\n",
      "2      2     Accept    2                      Balls to the Wall\n",
      "3      2     Accept    3                      Restless and Wild\n",
      "4      3  Aerosmith    5                               Big Ones\n",
      "\n",
      "\n",
      "   artid       name  aid                                  title\n",
      "0      1      AC/DC    1  For Those About To Rock We Salute You\n",
      "1      1      AC/DC    4                      Let There Be Rock\n",
      "2      2     Accept    2                      Balls to the Wall\n",
      "3      2     Accept    3                      Restless and Wild\n",
      "4      3  Aerosmith    5                               Big Ones\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "MergeError",
     "evalue": "Merge keys are not unique in right dataset; not a many-to-one merge",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMergeError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-0101d2f82798>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martists\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malbums\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'artid'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'one_to_many'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martists\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malbums\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'artid'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'many_to_one'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m#You can use 'many_to_many' without an error, since there is a duplicate key in one of the tables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m   7295\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7296\u001b[0m             \u001b[0mindicator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7297\u001b[1;33m             \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7298\u001b[0m         )\n\u001b[0;32m   7299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[0mindicator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m         \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m     )\n\u001b[0;32m     88\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    635\u001b[0m         \u001b[1;31m# are in fact unique.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalidate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 637\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_validate\u001b[1;34m(self, validate)\u001b[0m\n\u001b[0;32m   1271\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mright_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1272\u001b[0m                 raise MergeError(\n\u001b[1;32m-> 1273\u001b[1;33m                     \u001b[1;34m\"Merge keys are not unique in right dataset; \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1274\u001b[0m                     \u001b[1;34m\"not a many-to-one merge\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1275\u001b[0m                 )\n",
      "\u001b[1;31mMergeError\u001b[0m: Merge keys are not unique in right dataset; not a many-to-one merge"
     ]
    }
   ],
   "source": [
    "#Validating a merge\n",
    "\n",
    "import pandas as pd\n",
    "artists = pd.read_csv('datasets/artists.csv', sep=';')\n",
    "albums = pd.read_csv('datasets/albums.csv', sep=';')\n",
    "\n",
    "#You have been given 2 tables, artists, and albums. Use the console to merge them using\n",
    "#artists.merge(albums, on='artid').head(). Adjust the validate argument to answer which statement is False.\n",
    "\n",
    "print(artists.merge(albums, on='artid', validate='many_to_many').head())\n",
    "print('\\n')\n",
    "print(artists.merge(albums, on='artid', validate='one_to_many').head())\n",
    "print('\\n')\n",
    "print(artists.merge(albums, on='artid', validate='many_to_one').head())\n",
    "\n",
    "#You can use 'many_to_many' without an error, since there is a duplicate key in one of the tables.\n",
    "\n",
    "#You can use 'one_to_many' without error, since there is a duplicate key in the right table.\n",
    "\n",
    "#You can use 'many_to_one' without an error, since there is a duplicate key in the left table.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    pid   tid\n",
      "3    12  3479\n",
      "10   12  3439\n",
      "21   12  3445\n",
      "23   12  3449\n",
      "48   12  3437\n",
      "50   12  3435\n"
     ]
    }
   ],
   "source": [
    "#Concatenate and merge to find common songs\n",
    "\n",
    "import pandas as pd\n",
    "classic_18 = pd.read_csv('datasets/classic_18.csv')\n",
    "classic_19 = pd.read_csv('datasets/classic_19.csv')\n",
    "pop_18 = pd.read_csv('datasets/pop_18.csv')\n",
    "pop_19 = pd.read_csv('datasets/pop_19.csv')\n",
    "\n",
    "#The senior leadership of the streaming service is requesting your help again. You are given the historical files for a popular\n",
    "#playlist in the classical music genre in 2018 and 2019. Additionally, you are given a similar set of files for the most popular\n",
    "#pop music genre playlist on the streaming service in 2018 and 2019. Your goal is to concatenate the respective files to make a\n",
    "#large classical playlist table and overall popular music table. Then filter the classical music table using a semi-join to\n",
    "#return only the most popular classical music tracks.\n",
    "\n",
    "#The tables classic_18, classic_19, and pop_18, pop_19 have been loaded for you. Additionally, pandas has been loaded as pd.\n",
    "\n",
    "# Concatenate the classic tables vertically\n",
    "classic_18_19 = pd.concat([classic_18, classic_19], ignore_index=True)\n",
    "\n",
    "# Concatenate the pop tables vertically\n",
    "pop_18_19 = pd.concat([pop_18, pop_19], ignore_index=True)\n",
    "\n",
    "# Merge classic_18_19 with pop_18_19\n",
    "classic_pop = classic_18_19.merge(pop_18_19, on='tid')\n",
    "\n",
    "# Using .isin(), filter classic_18_19 rows where tid is in classic_pop\n",
    "popular_classic = classic_18_19[classic_18_19['tid'].isin(classic_pop['tid'])]\n",
    "\n",
    "# Print popular chart\n",
    "print(popular_classic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
